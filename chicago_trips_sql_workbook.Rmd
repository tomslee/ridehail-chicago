---
title: "Chicago Ridehail: Trips Workbook"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  number_sections: true
  df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

# Setup and connect

No text needed here.

```{r setup, include=FALSE, echo=FALSE}
# install.packages("librarian")
librarian::shelf(tidyverse, knitr, reshape2, ggtext, 
                 jsonlite, stringr, lubridate, scales, 
                 ggthemes, RColorBrewer, viridis, vroom,
                 janitor, RPostgres, pals
                 )

knitr::opts_knit$set(echo = FALSE)
#update_geom_defaults("point", aes(shape=21, fill="white", size=2, stroke=2, colour="Steel Blue"))
update_geom_defaults("point", aes(shape=16, alpha=1.0))
update_geom_defaults("line", aes(linewidth=1, alpha=1.0))
update_geom_defaults("bar", aes(shape=16, alpha=1.0, size=3, fill="Steel Blue"))
```

```{r postgresql, include=FALSE, echo=FALSE}
# AWS
# The password is stored in a pgpass file (~/.pgpass, or %APPDATA%\postgresql\pgpass.conf on Windows)
con <- dbConnect(RPostgres::Postgres(),
                 host="database-1.cxkc40qycf2y.us-east-2.rds.amazonaws.com",
                 port=5432,
                 dbname="postgres",
                 user="rhreader")
```

# "Upfront fare" variance experiments

Can we say anything about the extent to which Uber "upfront fares" have
made fares deviate from the "rate card" calculation? (Note: "upfront
fares" is different to "upfront rates" that now control how much drivers
earn on a trip in many US markets).

Data set notes from [Chicago Data
Portal](https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips-2023-/n26f-ihde/about_data):

-   trip_id: A unique identifier for the trip.
-   trip_start_timestamp: When the trip started, rounded to the nearest
    15 minutes.
-   trip_second: Time of the trip in seconds. (I convert this to
    minutes).
-   trip_miles: Distance of the trip in miles.
-   fare: The fare for the trip, rounded to the nearest \$2.50.

## Upfront fares in Chicago

-   A [reddit
    post](https://www.reddit.com/r/uber/comments/xrkdhf/uber_upfront_prices_live_in_chicago/)
    from September 2022 says "Uber upfront prices live in Chicago". Does
    it mean fares or pay?
-   [The rideshare
    guy](https://therideshareguy.com/upfront-pricing-for-drivers/) says
    that Upfront pricing for drivers (i.e. upfront pay) is coming to
    Chicago on Sept 2022.

```{r upfront-parameters, echo=FALSE}
years <- 2020
months <- list(4, 8, 12)
first_thursday_list_feb <- list("2019-02-07", 
                            "2020-02-06", 
                            "2021-02-04", 
                            "2022-02-03", 
                            "2023-02-02", 
                            "2024-02-01")
first_thursday_list_jun <- list("2019-06-06",
                            "2020-06-04", 
                            "2021-06-03", 
                            "2022-06-02", 
                            "2023-06-01", 
                            "2024-06-06")
first_thursday_list_oct <- list("2019-10-03",
                            "2020-10-01", 
                            "2021-10-07", 
                            "2022-10-06", 
                            "2023-10-05", 
                            "2024-10-03")
first_thursdays = list(first_thursday_list_feb, first_thursday_list_jun, first_thursday_list_oct)
#first_seven_dates <- seq(ymd(sprintf("%s-%s-01", year, month)),
#                         ymd(sprintf("%s-%s-07", year, month)),
#                         by="1 day")
#first_thursday <- first_seven_dates[wday(first_seven_dates, label=TRUE)=="Thu"]
# test_date <- format(first_thursday, "%Y-%m-%d")
pickup_community_area = 4
```

# Build models for a list of community areas

The data collected is for the first Thursday of February, June, and
October for each year. I collected it by downloading a query result from
the Chicago web site and uploading it to PostgreSQL using the pgsql
\\copy command. It is stored in a table "ridehail.trip_fare" and models
are built from a cleaned data set accessed through the view
"ridehail.trip_fares", which filters out trips with missing fields that
are important for the models.

```{r model, eval=FALSE, echo=FALSE}
pickup_community_area_list = list(0)
years <- list(2024)
months <- list(4, 8)
# model_type <- "zero"
# model_type <- "lm"
model_type <- "zero40"

if (pickup_community_area_list[[1]] == 0){
    sql <- {"select 0 as pickup_community_area, year, month, trip_id, trip_miles, 
    trip_minutes, fare, additional_charges
  	from ridehail.trip_fares 
  	where year = $1 and month = $2"
    } 
  sql_agg <- {"select 0 as pickup_community_area,
    trip_start_timestamp::date as model_date, year,	month,
  	count(*) as trip_count, 
  	avg(trip_miles) as mean_trip_miles,
  	avg(trip_minutes) as mean_trip_minutes, avg(fare) as mean_fare,
  	avg(fare + additional_charges) as mean_total_fare
    from ridehail.trip_fares
  	where year = $1 and month = $2
    group by 1, model_date, year, month"
  } 
} else {
  sql <- {"select pickup_community_area, year, month, trip_id, trip_miles,
    trip_minutes, fare, additional_charges
  	from ridehail.trip_fares 
  	where pickup_community_area = $1
    and year = $2 and month = $3"
    } 
  
  sql_agg <- {"select pickup_community_area, 
    trip_start_timestamp::date as model_date, year, month,
  	count(*) as trip_count, 
  	avg(trip_miles) as mean_trip_miles,
  	avg(trip_minutes) as mean_trip_minutes, avg(fare) as mean_fare,
  	avg(fare + additional_charges) as mean_total_fare
    from ridehail.trip_fares
  	where pickup_community_area = $1
  	and year = $2 and month = $3
    group by pickup_community_area, model_date, year, month"} 
}

for (pickup_community_area in pickup_community_area_list){
  for (this_year in years) {
    for (this_month in months){
        s_date <- sprintf("%s-%s", this_year, this_month)
        # Get aggregates
        rs_agg <- dbSendQuery(con,sql_agg)
        if (pickup_community_area==0){
          dbBind(rs_agg, list(this_year, this_month))
        } else {
          dbBind(rs_agg, list(pickup_community_area, this_year, this_month))
        }
        tb_agg <- as_tibble(dbFetch(rs_agg, n=-1))
        dbClearResult(rs_agg)
        if(nrow(tb_agg) == 0){ next }
        # Now compute the model
        rs <- dbSendQuery(con,sql)
        if (pickup_community_area==0){
          dbBind(rs, list(this_year, this_month))
        } else {
          dbBind(rs, list(pickup_community_area, this_year, this_month))
        }
        tb_sql <- as_tibble(dbFetch(rs, n=-1))
        dbClearResult(rs)
        
        if(nrow(tb_sql) > 0){
          if (model_type=="lm"){
            model <- lm(fare ~ trip_miles + trip_minutes, data=tb_sql)
            coeff_intercept <- summary(model)$coefficients["(Intercept)", "Estimate"]
          } else if (model_type=="zero"){
            model <- lm(fare ~ 0 + trip_miles + trip_minutes, data=tb_sql)
            coeff_intercept <- 0.0
          } else if (model_type=="zero40") {
            model <- lm(fare ~ 0 + trip_miles + trip_minutes, data=tb_sql %>% filter(trip_miles<=40))
            coeff_intercept <- 0.0
          }
          # coeff_intercept[s_year] <- 0
          s <- summary(model)
          coeff_miles <- s$coefficients[["trip_miles", "Estimate"]]
          coeff_minutes <- s$coefficients[["trip_minutes", "Estimate"]]
          rse <- s$sigma
          tb_result <- tb_agg %>% 
            mutate(coeff_per_mile=coeff_miles,
                   coeff_per_minute=coeff_minutes,
                   coeff_intercept=coeff_intercept,
                   rse=rse,
                   model_type=model_type,
                   last_updated=Sys.time())
          ## Commented out in case I run this by mistake
          dbAppendTable(con, "trip_model", tb_result)
        }
        print(tb_result)
    }
  }
}
```

# Analysis: Chicago overview

Testing the data set by the total number of trips each day. It is similar enough to the accurate numbers recorded elsewhere.

```{r fare_model, echo=FALSE}
sql <- {"select 
  to_date(year || '-' || month || '-01', 'YYYY-MM-DD') as trip_date, 
  trips
  from (
    select year, month, count(*) as trips 
    from ridehail.trip_fares 
    group by year, month
    order by year, month) as T"
  }
rs <- dbSendQuery(con,sql)
tb <- as_tibble(dbFetch(rs, n=-1))
# Clear the result
dbClearResult(rs)

p <- ggplot(data=tb, aes(x=trip_date, y=trips, 
                             colour="dummy"))
p + 
  #facet_wrap(vars(measure), scales="free") +
  geom_line() +
  labs(title="TNC recorded trips with non-zero time recorded, per month in Chicago",
       subtitle="Trips on the first Thursday of the month",
       caption={"The low June 2019 number is a data collection artifact: 
         many trips in the Chicago data set are missing the trip_seconds field for that month"},
         x="Date",
         y="Recorded Trips") + 
  scale_y_continuous(limits=c(0, NA)) +
  theme(legend.position="none") +
  scale_colour_brewer(palette = "Dark2")
```

# Analysis: details for a specific community area

```{r plot_experiment, echo=FALSE}
pickup_community_area = 47
years <- 2019:2024
months <- list(2, 6, 10)
rm(tb_model_detail)
for (this_year in years) {
  for (this_month in months){
      s_date <- sprintf("%s-%s", this_year, this_month)
      sql <- {"select year, month, trip_id, trip_miles, 
        trip_minutes, fare, additional_charges
      	from ridehail.trip_fares 
      	-- where pickup_community_area = $1
      	-- and year = $2 and month = $3
        where year = $1 and month = $2"
        } 
      rs <- dbSendQuery(con,sql)
      # dbBind(rs, list(pickup_community_area, this_year, this_month))
      dbBind(rs, list(this_year, this_month))
      tb_sql <- as_tibble(dbFetch(rs, n=-1)) 
      dbClearResult(rs)
      if(nrow(tb_sql) > 0){
        model <- lm(fare ~ trip_miles + trip_minutes, data=tb_sql)
        coeff_intercept <- summary(model)$coefficients["(Intercept)", "Estimate"]
        coeff_miles <- summary(model)$coefficients["trip_miles", "Estimate"]
        coeff_minutes <- summary(model)$coefficients["trip_minutes", "Estimate"]
        rse <- summary(model)$sigma
        tb_result <- tb_sql %>% 
          mutate(rate_card_fare=round((coeff_miles * trip_miles + 
                                         coeff_minutes * trip_minutes +
                                         coeff_intercept)/2.5) * 2.5) %>%
          mutate(residual=fare - rate_card_fare) %>%
          select(c(year, month, trip_id, fare, rate_card_fare, residual))
        if(exists("tb_model_detail")){
          tb_model_detail <- union(tb_model_detail, tb_result)
        } else {
          tb_model_detail <- tb_result  
        }
      }
  }
}

p <- ggplot(data=tb_model_detail, 
            mapping=aes(x=rate_card_fare, y=fare, colour=as.factor(year)))

p +
  facet_wrap(vars(year), scales = "free_y") +
  geom_point(size=2, alpha=0.05) +
  geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title=sprintf("Chicago ridehail, Community Area %s: actual vs best-fit time & distance fares", 
                     pickup_community_area ),
       x="Best fit time & distance fare (to nearest $2.50)",
       y="Actual fare (to nearest $2.50)") +
  scale_x_continuous(limits=c(0, 40)) +
  scale_y_continuous(limits=c(0, 40)) +
  theme(legend.position = "none", legend.title=element_blank()) +
  scale_colour_brewer(palette="Dark2")
```

## A second approach: plotting errors directly

```{r plot_experiment_2, echo=FALSE}
# Another way of plotting errors
p <- ggplot(data=tb_model_detail, 
            mapping=aes(x=rate_card_fare, y=residual, colour="dummy", fill=as.factor(year)))
p +
  facet_wrap(vars(year), scales = "free_y") +
  geom_point(size=2, alpha=0.05) +
  geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title=sprintf("Chicago ridehail, Community Area %s: deviation from time & distance fares", 
                     pickup_community_area ),
       x="Best fit time & distance fare (to nearest $2.50)",
       y="Deviation from time & distance fare ($)") +
  scale_x_continuous(limits=c(0, 40)) +
  scale_y_continuous(limits=c(-30, +30)) +
  theme(legend.position = "none", legend.title=element_blank()) +
  scale_colour_brewer(palette="Dark2")
```

# Analysis: which community areas are busy?

```{r ca_trip_counts, echo=FALSE}
sql <- {"select pickup_community_area, count(*) as recorded_trips,
               100.0 * count(*)/(sum(count(*)) over ()) as trip_percent
        from ridehail.trip_fares
        group by pickup_community_area
        order by trip_percent desc"
  } 
rs <- dbSendQuery(con,sql)
# dbBind(rs, list(pickup_community_area))
tb <- as_tibble(dbFetch(rs, n=-1))
tb <- tb %>% slice_max(trip_percent, n=20)
dbClearResult(rs)

p <- ggplot(data=tb, 
            mapping=aes(x=reorder(pickup_community_area, -trip_percent), 
                        y=trip_percent, 
                        colour="dummy",
                        fill="dummy"))

p +
  geom_bar(stat="identity", width=0.8) +
  labs(title="Chicago ridehail: trips by Community Area",
       x="Community Area",
       y="Percentage of recorded trips") +
  theme(legend.position="none") +
  scale_y_continuous(limits=c(0, NA)) +
  theme(legend.title=element_blank()) +
  scale_colour_brewer(palette="Dark2") +
  scale_fill_brewer(palette="Dark2")
```

# Analysis: has the distribution of trips changed?

Take a busy downtown community area (8, 32) and compare it to a
low-traffic area (47, 55).

TODO: Better to compare to the total for each month, and probably a more
concise query.

```{r ca_changing_traffic, echo=FALSE}
sql <- {"select pickup_community_area, T1.model_date, 
        (recorded_trips::float / recorded_trips_8::float) as ratio8 
        from
        (select pickup_community_area, 
        		trip_start_timestamp::date as model_date, 
        		count(*) as recorded_trips
        	from ridehail.trip_fares
        	group by pickup_community_area, model_date) as T1 
        inner join 
        (select trip_start_timestamp::date as model_date, 
        		count(*) as recorded_trips_8
        from ridehail.trip_fares
        where pickup_community_area = 8
        group by model_date) as T2 
        on T1.model_date = T2.model_date;"
  } 
rs <- dbSendQuery(con,sql)
# dbBind(rs, list(pickup_community_area))
tb <- as_tibble(dbFetch(rs, n=-1))
dbClearResult(rs)

p <- ggplot(data=tb %>% filter(pickup_community_area %in% c(8, 32, 7, 36, 47, 55)), 
            mapping=aes(x=model_date, 
                        y=ratio8, 
                        colour="dummy",
                        fill="dummy"))

p +
  facet_wrap(vars(pickup_community_area), scales="free_y") +
  geom_line() +
  labs(title="Chicago ridehail: trips by Community Area (compared to CA 8)",
       subtitle="Conclusion: a slight shift to less busy areas",
       x="Community Area",
       y="Fraction of recorded trips compared to CA 8") +
  theme(legend.position="none") +
  scale_y_continuous(limits=c(0, NA)) +
  theme(legend.title=element_blank()) +
  scale_colour_brewer(palette="Dark2") +
  scale_fill_brewer(palette="Dark2")
```

# Analysis: aggregate changes over time

```{r ca_aggregate_plot, echo=FALSE}
pickup_community_area_list = list(0)
index = 0
mean_trip_miles = 6.112
mean_trip_minutes = 18.260
for(pickup_community_area in pickup_community_area_list){
  index = index + 1
  sql <- {"select pickup_community_area, 
    model_date, 
  	-- cast(trip_count as numeric) as trip_count, 
  	mean_trip_miles,
  	mean_trip_minutes, 
  	mean_fare,
  	mean_fare / mean_trip_miles as mean_fare_per_mile,
  	mean_fare / mean_trip_minutes as mean_fare_per_minute
  	-- coeff_per_mile,
  	-- coeff_per_minute,
  	-- coeff_intercept,
  	-- rse
  	from ridehail.trip_model
  	where pickup_community_area = $1
    and model_type = 'zero'"
  } 
  rs <- dbSendQuery(con,sql)
  dbBind(rs, list(pickup_community_area))
  tb_tmp <- as_tibble(dbFetch(rs, n=-1))
  dbClearResult(rs)
  if(index > 1){
    tb <- union(tb, tb_tmp)
  } else {
    tb <- tb_tmp
  }
}

#trip_count,coeff_per_mile,coeff_per_minute,coeff_intercept,rse,mean_trip_miles,mean_trip_minutes,mean_fare
                 
tb <- tb %>%
  pivot_longer(!c(pickup_community_area, 
                  model_date),
               names_to="category", values_to="measure"
               ) 

p <- ggplot(data=tb, 
            mapping=aes(x=model_date, 
                        y=measure, 
                        colour="dummy"),
                        fill="dummy")


p +
  facet_wrap(vars(category), scales = "free_y") +
  geom_line() +
  #geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title=sprintf("Chicago ridehail trends: Community Area %s",
                     pickup_community_area),
       x="Date",
       y="value",
       colour="Pickup Community Area") +
  theme(legend.position="none") +
  scale_y_continuous(limits=c(0, NA)) +
  theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2")
```

# Analysis: model RSE and intercept etc

```{r ca_model_plot, echo=FALSE}
pickup_community_area_list = list(0)
index = 0
mean_trip_miles = 6.112
mean_trip_minutes = 18.260
for(pickup_community_area in pickup_community_area_list){
  index = index + 1
  sql <- {"select pickup_community_area, 
    model_date, model_type, 
  	-- cast(trip_count as numeric) as trip_count, 
  	-- mean_trip_miles,
  	-- mean_trip_minutes, 
  	-- mean_fare,
  	coeff_per_mile,
  	coeff_per_minute,
  	coeff_intercept,
  	rse
  	from ridehail.trip_model
  	where pickup_community_area = $1"
  } 
  rs <- dbSendQuery(con,sql)
  dbBind(rs, list(pickup_community_area))
  tb_tmp <- as_tibble(dbFetch(rs, n=-1))
  tb_tmp <- tb_tmp %>% 
    mutate(mean_trip_cost=mean_trip_miles * coeff_per_mile + mean_trip_minutes * coeff_per_minute + coeff_intercept)
  dbClearResult(rs)
  if(index > 1){
    tb <- union(tb, tb_tmp)
  } else {
    tb <- tb_tmp
  }
}

#trip_count,coeff_per_mile,coeff_per_minute,coeff_intercept,rse,mean_trip_miles,mean_trip_minutes,mean_fare
                 
tb <- tb %>%
  pivot_longer(!c(pickup_community_area, 
                  model_date,
                  model_type),
               names_to="category", values_to="measure"
               ) 

p <- ggplot(data=tb, 
            mapping=aes(x=model_date, 
                        y=measure, 
                        colour=model_type),
                        fill=model_type)


p +
  facet_wrap(vars(category), scales = "free_y") +
  geom_line() +
  #geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title=sprintf("Chicago ridehail trends: Community Area %s",
                     pickup_community_area),
       x="Date",
       y="value",
       colour="Pickup Community Area") +
  # theme(legend.position="none") +
  scale_y_continuous(limits=c(0, NA)) +
  theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2")
```

# Analysis: actual and predicted fares as a function of distance

## values, binned

```{r model_fares_distance, echo=FALSE}

sql <- {"select model_date, bin_max, avg(fare) as mean_bin_fare, avg(trip_miles) as mean_bin_miles, 
	avg(60.0 * trip_miles/trip_minutes) as mean_bin_mph, cast(count(*) as numeric) as trip_count, 
	avg(coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) as mean_bin_model_fare
from
	(select model_date, trip_miles, trip_minutes, fare, coeff_per_mile, coeff_per_minute,
	round((5 + trip_miles)/ 10) * 10 as bin_max
	from ridehail.trip_fares 
	inner join ridehail.trip_model
	on ridehail.trip_fares.year = date_part('year', ridehail.trip_model.model_date)  
	and ridehail.trip_fares.month = date_part('month', ridehail.trip_model.model_date)  
	where ridehail.trip_model.pickup_community_area = 0
	and ridehail.trip_model.model_type = 'zero40'
	and ridehail.trip_fares.trip_miles < 40
	and trip_minutes > 0) as T
group by bin_max, model_date
order by bin_max, model_date"}

rs <- dbSendQuery(con,sql)
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

tb_plot <- tb %>%
 mutate(model_diff = mean_bin_fare - mean_bin_model_fare) %>%
 pivot_longer(!c(model_date, bin_max),
               names_to="category", values_to="measure"
               ) 

p <- ggplot(data=tb_plot, 
            mapping=aes(x=model_date, 
                        y=measure, 
                        colour=as.factor(bin_max)))
p +
  facet_wrap(vars(category), scales = "free_y") +
  geom_line() +
  # geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title="Chicago ridehail trends: fares vs distance",
       x="Date",
       y="Measure",
       colour="Distance (bin max)") +
  # scale_y_continuous(limits=c(0, NA)) +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2") 
```

## changed, binned

```{r model_fares_change, echo=FALSE}

sql <- {"select model_date, bin_max, 
	mean_bin_fare,
	mean_bin_model_fare,
	(100.0 * mean_bin_fare / first_value(mean_bin_fare) over w)  as percent_first_mean_bin_fare,
	(100.0 * mean_bin_model_fare / first_value(mean_bin_model_fare) over w)  as percent_first_mean_bin_model_fare
from (
select model_date, bin_max, avg(fare) as mean_bin_fare, avg(trip_miles) as mean_bin_miles, 
	avg(60.0 * trip_miles/trip_minutes) as mean_bin_mph, cast(count(*) as numeric) as trip_count, 
	avg(coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) as mean_bin_model_fare
from
	(select model_date, trip_miles, trip_minutes, fare, coeff_per_mile, coeff_per_minute,
	round((5 + trip_miles)/ 10) * 10 as bin_max
	from ridehail.trip_fares 
	inner join ridehail.trip_model
	on ridehail.trip_fares.year = date_part('year', ridehail.trip_model.model_date)  
	and ridehail.trip_fares.month = date_part('month', ridehail.trip_model.model_date)  
	where ridehail.trip_model.pickup_community_area = 0
	and ridehail.trip_model.model_type = 'zero'
	and ridehail.trip_fares.trip_miles < 40
	and trip_minutes > 0) as T
group by bin_max, model_date
order by bin_max, model_date
) as T
window w as (partition by bin_max order by model_date);"}

rs <- dbSendQuery(con,sql)
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

tb_plot <- tb %>%
 mutate(model_diff = mean_bin_fare - mean_bin_model_fare) %>%
 pivot_longer(!c(model_date, bin_max),
               names_to="category", values_to="measure"
               ) 

p <- ggplot(data=tb_plot, 
            mapping=aes(x=model_date, 
                        y=measure, 
                        colour=as.factor(bin_max)))
p +
  facet_wrap(vars(category), scales = "free_y") +
  geom_line() +
  # geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title="Chicago ridehail trends: fares vs distance",
       x="Date",
       y="Measure",
       colour="Distance (bin max)") +
  # scale_y_continuous(limits=c(0, NA)) +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2") 
```

## Looking more closely at RSE

Are there patterns we can pick out? The absence of patterns based on obvious global variables (time of day, distance) suggests personalization / 
surveillance.

```{r rse_1, echo=FALSE}
pickup_community_area=32
year=2024
month=6
sql <- {"select trip_id, date_part('hour', trip_start_timestamp::time) as hour, trip_miles, trip_minutes, fare, 
	(coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) as model_fare,
	round((5 + trip_miles)/ 10) * 10 as bin_max,
	((coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) - fare) as trip_deviation,
	(100.0 * ((coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) - fare)/ fare ) as trip_deviation_percent
from ridehail.trip_fares f inner join ridehail.trip_model m
on f.year = m.year and f.month = m.month 
and f.pickup_community_area = m.pickup_community_area
and m.model_type = 'zero'
where f.pickup_community_area = $1
and f.year = $2 and f.month = $3
and fare > 0"}

rs <- dbSendQuery(con,sql)
dbBind(rs, list(pickup_community_area, year, month))
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

p <- ggplot(data=tb %>% filter(bin_max < 40) %>% mutate(bin=as.factor(bin_max)), 
            mapping=aes(x=hour, 
                        y=trip_deviation_percent, 
                        colour=bin))
p +
  facet_wrap(vars(bin_max)) +
  geom_point(alpha=0.1) +
  # geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title="Chicago ridehail trends: deviations in CA 8, 2024-06",
       subtitle="If deviations come from global demand/traffic trends, there would be time-based differences.",
       x="Hour",
       y="Trip deviation from distance/time fit (% of fare)") +
  scale_y_continuous(limits=c(-100, +100)) + # , trans='log10') +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2")
```

```{r rse_aggregate, echo=FALSE}
pickup_community_area=8
year=2023
month=10
sql <- {"select bin_max, hour, 
	avg(trip_deviation) as mean_deviation, 
	avg(trip_deviation_percent) as mean_deviation_percent,
	stddev(trip_deviation) as stddev_deviation, 
	stddev(trip_deviation_percent) as stddev_deviation_percent
from
( select trip_id, date_part('hour', trip_start_timestamp::time) as hour, trip_miles, trip_minutes, fare, 
	(coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) as model_fare,
	round((5 + trip_miles)/ 10) * 10 as bin_max,
	((coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) - fare) as trip_deviation,
	(100.0 * ((coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) - fare)/ fare ) as trip_deviation_percent
from ridehail.trip_fares f inner join ridehail.trip_model m
on f.year = m.year and f.month = m.month 
and f.pickup_community_area = m.pickup_community_area
and m.model_type = 'zero'
where f.pickup_community_area = $1
and f.year = $2 and f.month = $3 ) as T
group by bin_max, hour;"}

rs <- dbSendQuery(con,sql)
dbBind(rs, list(pickup_community_area, year, month))
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

p <- ggplot(data=tb %>% filter(bin_max < 40) %>% mutate(bin=as.factor(bin_max)), 
            mapping=aes(x=hour, 
                        y=mean_deviation_percent, 
                        colour=bin))
p +
  facet_wrap(vars(bin_max)) +
  geom_line() +
  # geom_smooth(method="lm", se=FALSE, fullrange=FALSE, level=0.95) +
  labs(title=sprintf("Chicago ridehail trends: aggregate deviations in CA %s, %s-%s", pickup_community_area, year, month),
       subtitle="If deviations come from global demand/traffic trends, there would be time-based differences.",
       caption="What does the bin-based difference tell us? That the fit over-corrects on time?",
       x="Hour of the day",
       y="Mean trip deviation from distance/time fit (% of fare)") +
  # scale_y_continuous(limits=c(-100, +100)) + # , trans='log10') +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2")
```

## Deviations from models

```{r, deviation, echo=FALSE}

month = 2
sql <- {"with T1 as (select model_date, ridehail.trip_fares.year as year, ridehail.trip_fares.month as month, 
	trip_miles, trip_minutes, fare, coeff_per_mile, coeff_per_minute,
	(coeff_per_mile * trip_miles + coeff_per_minute * trip_minutes) as best_fit_fare
	from ridehail.trip_fares inner join ridehail.trip_model
		on ridehail.trip_fares.year = ridehail.trip_model.year  
		and ridehail.trip_fares.month = ridehail.trip_model.month
	where ridehail.trip_model.pickup_community_area = 0
	and ridehail.trip_model.model_type = 'zero'
	and ridehail.trip_fares.fare > 1
	and ridehail.trip_fares.trip_miles < 60 )
select model_date, deviation_percent_bin, trips_in_bin, 
	(100.0 * trips_in_bin / (sum(trips_in_bin) over (partition by (model_date)))) as trip_percent_in_bin
from
	( select model_date, deviation_percent_bin, count(*) trips_in_bin
	from
	(select model_date, year, month, trip_miles, trip_minutes, fare, best_fit_fare, 
		round(100 * (fare - best_fit_fare)/best_fit_fare) as deviation_percent,
		10 * round(10 * (fare - best_fit_fare)/best_fit_fare) as deviation_percent_bin
	from T1 ) as T2
	group by model_date, deviation_percent_bin ) as T3
order by model_date, deviation_percent_bin;"}

rs <- dbSendQuery(con,sql)
#dbBind(rs, list(year, month))
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

p <- ggplot(data=tb %>% filter(month(model_date) == month) %>% mutate_at(vars(model_date), factor), 
            mapping=aes(x=deviation_percent_bin, 
                        y=trip_percent_in_bin, 
                        colour=model_date))
p +
  geom_line() +
  labs(title=sprintf("Chicago ridehail trends: deviations for each %s", month),
       subtitle="If deviations come from global demand/traffic trends, there would be time-based differences.",
       #caption="What does the bin-based difference tell us? That the fit over-corrects on time?",
       x="Deviation (% of predicted trip fare)",
       y="Percent of trips") +
  scale_x_continuous(limits=c(-100, +100)) + # , trans='log10') +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  # scale_colour_tableau(palette = "Hue Circle")
  scale_colour_manual(values=as.vector(pals::alphabet()))
```
# Fare variation

```{r fig-fare-variation, echo=FALSE}
target_month = 6
sql <- {"select year, month, bin, trips_in_bin,
	(100.0 * trips_in_bin / (sum(trips_in_bin) over (partition by (year, month)))) as trip_percent_in_bin
from
(select year, month, bin, count(*) as trips_in_bin
from
	(select year, month, fare, round(fare /10) * 10 as bin
	from ridehail.trip_fares
	where fare > 0) as T
group by year, month, bin) as T2
order by year, month, bin;"}

rs <- dbSendQuery(con,sql)
#dbBind(rs, list(year, month))
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

p <- ggplot(data=tb %>% 
              filter(month == target_month,
                     bin <= 50) %>% 
              mutate(fare_date=as.Date(sprintf("%s-%s-01", year, month))), 
            mapping=aes(x=as.factor(bin), 
                        y=trip_percent_in_bin, 
                        colour=as.factor(year),
                        fill=as.factor(year)))
p +
  #geom_line() +
  geom_col(position = "dodge", alpha=0.7) +
  labs(title=sprintf("Chicago fare distributions for each %s", month.name[target_month]),
       x="Fare bin (mid-point)",
       y="Percent of trips",
       colour="Year",
       fill="Year") +
  # scale_x_discrete(limits=c(0, +100)) + # , trans='log10') +
  # theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  #scale_fill_manual(values=as.vector(pals::alphabet())) +
  #scale_colour_manual(values=as.vector(pals::alphabet()))
  scale_fill_brewer(palette="Dark2") +
  scale_colour_brewer(palette="Dark2")

```


# Plotting supply and demand


```{r, monopoly, echo=FALSE}
f_supply <- function(x){
  x
}
f_demand <- function(x){
  10 - x
}
mydata <- data.frame(x=seq(0,10, 0.5))
mydata <- data.frame(x=seq(0, 10, 0.5),
                    supply = sapply(mydata$x, FUN = f_supply),
                    demand = sapply(mydata$x, FUN = f_demand))

p <-  ggplot(mydata, aes(x=x, y = supply)) + xlim(0, 10)

p + 
  geom_function(fun = f_supply) +
  geom_function(fun = f_demand) + 
  labs(x="Quantity", y="Price") +
  geom_ribbon(data=subset(mydata, x<=5), 
              aes(ymin=5, ymax=demand), fill="red", alpha=0.2,) + 
  geom_ribbon(data=subset(mydata, x<=2.5), 
              aes(ymin=7.5, ymax=demand), fill="blue", alpha=0.2,) +
  annotate("segment", x = 0, y = 5, xend = 5, yend = 5, linetype="dashed", color="red") +
  annotate("segment", x = 5, y = 0, xend = 5, yend = 5, linetype="dashed", color="red")  +
  annotate("segment", x = 0, y = 7.5, xend = 2.5, yend = 7.5, linetype="dashed", color="blue") +
  annotate("segment", x = 2.5, y = 2.5, xend = 2.5, yend = 7.5, linetype="dashed", color="blue")  +
  annotate("label", x = 9, y = 1, label = "Demand") + #, label.size=0) +
  annotate("label", x = 9, y = 9, label = "Supply") +
  annotate("label", x = 5, y = 5, hjust="left", label = "Competition", colour="red") +
  annotate("label", x = 1.25, y = 6, hjust="left", label = "Consumer surplus\n(competition)", fill="white", colour="red") +
  annotate("label", x = 2.5, y = 7.5, hjust="left", label = "Monopoly", colour="blue") +
  annotate("label", x = 0.25, y = 8.5, hjust="left", label = "Consumer surplus\n(monopoly)", colour="blue") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

# Additional charges

```{r additional-charges, echo=FALSE}
sql <- {"select 
to_date(year || '-' || month || '-01', 'YYYY-MM-DD') as trip_date,
fare, fare_plus_charges, modal_additional_charge, additional_charges, avg_a_over_f, avg_a_over_avg_f from
(select year, month, avg(fare) as fare, avg(fare + additional_charges) as fare_plus_charges, 
  avg(additional_charges) as additional_charges, 
  mode() within group (order by additional_charges) as modal_additional_charge,
  avg(additional_charges/fare) as avg_a_over_f,
  avg(additional_charges)/avg(fare) as avg_a_over_avg_f
  from ridehail.trip_fares
group by year, month) as T"}

rs <- dbSendQuery(con,sql)
#dbBind(rs, list(year, month))
tb <- as_tibble(dbFetch(rs, n=-1)) 
dbClearResult(rs)

tb_plot <- tb %>% pivot_longer(!trip_date,
               names_to="category", values_to="measure"
               ) 

p <- ggplot(data=tb_plot, 
            mapping=aes(x=trip_date, 
                        y=measure, 
                        colour=category))
p +
  facet_wrap(vars(category), scales="free") +
  geom_line() +
  labs(title="Chicago ridehail trends: additional charges",
       caption={
       "Additional charges are supposed to be mainly fixed charges, not proportional to the fare,
         yet they have been increasing along with fares"},
       x="Date",
       y="Value") +
  # scale_x_continuous(limits=c(-100, +100)) + # , trans='log10') +
  theme(legend.position="none") +
  # theme(legend.title=element_blank()) +
  scale_colour_brewer(palette = "Dark2")
```

```